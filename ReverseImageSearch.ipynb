{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","from tqdm import tqdm\n","from PIL import Image\n","import csv"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import torch\n","from torchvision import models\n","from torchvision import transforms"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import numpy as np\n","from numpy.linalg import norm\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["<h1 style=\"font-family: 'Times New Roman'\">Reshaping and Cleaning</h1>\n","\n","Before we vectorize the images, we must format them properly for the CNN. Images are reshaped to (3, 224, 224) and saved in the directory inputImagesCNN.\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# needed input dimensions for the CNN\n","inputDim = (224,224)\n","inputDir = \"./images\"\n","inputDirCNN = \"inputImagesCNN\"\n","\n","os.makedirs(inputDirCNN, exist_ok = True)\n","\n","transformationForCNNInput = transforms.Compose([transforms.Resize(inputDim)])\n","\n","# os.walk to extract the images from the root folder \n","paths = {}\n","for path, dir, imageNames in os.walk(inputDir):\n","    for imageName in imageNames:\n","        # ignores invisible files\n","        if imageName.startswith(\".\"):\n","            continue\n","        # Open image and convert any grayscale to RBG.\n","        I = Image.open(os.path.join(path, imageName)).convert('RGB')\n","        newI = transformationForCNNInput(I)\n","\n","        paths[imageName] = path\n","\n","        # sav images to CNN path\n","        newI.save(os.path.join(inputDirCNN, imageName))\n","        \n","        newI.close()\n","        I.close()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["with open('paths.csv', 'w') as csv_file:  \n","    writer = csv.writer(csv_file)\n","    for key, value in paths.items():\n","       writer.writerow([key, value])"]},{"cell_type":"markdown","metadata":{},"source":["<h1 style=\"font-family: 'Times New Roman'\">Vecorization Algorithm</h1>\n","\n","Vectorization is the process of turning some input into a vector. I am using the torch Img2VecResnet18 CNN to vectorize the image data. It is a pretrained network The model takes in a (3, 224, 224) image file and returns a (1, 512) array."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from resources import Img2VecResnet18"]},{"cell_type":"markdown","metadata":{},"source":["<h1 style=\"font-family: 'Times New Roman'\">Vectorize Dataset</h1>\n","\n","Applies our vectorization algorithm to the image dataset and creates a dictionary with the filenames as keys and the vectors as the values."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Converting images to feature vectors:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8446/8446 [04:30<00:00, 31.26it/s]\n"]}],"source":["import numpy\n","# generate vectors for all the images in the set\n","img2vec = Img2VecResnet18() \n","\n","allVectors = {}\n","print(\"Converting images to feature vectors:\")\n","for image in tqdm(os.listdir(\"inputImagesCNN\")):\n","    if image.startswith(\".\"):\n","        continue\n","    I = Image.open(os.path.join(\"inputImagesCNN\", image))\n","    vec = img2vec.getVec(I)\n","    allVectors[image] = vec\n","    I.close() "]},{"cell_type":"markdown","metadata":{},"source":["<h1 style=\"font-family: 'Times New Roman'\">Store Vectors as CSV</h1>\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["np.savez_compressed('vectors.npz', **allVectors)"]},{"cell_type":"markdown","metadata":{},"source":["<h1 style=\"font-family: 'Times New Roman'\">Shape and Clean Search Images</h1>\n","\n","Shapes search images into (3, 224, 224) file. "]},{"cell_type":"markdown","metadata":{},"source":["<h1 style=\"font-family: 'Times New Roman'\">"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inputDim = (224,224)\n","searchDir = \"./searchImages\"\n","searchDirCNN = \"searchImagesCNN\"\n","\n","os.makedirs(searchDirCNN, exist_ok = True)\n","\n","transformationForCNNInput = transforms.Compose([transforms.Resize(inputDim)])\n","\n","for path, dir, imageNames in os.walk(searchDir):\n","    for imageName in imageNames:\n","        # ignores invisible files\n","        if imageName.startswith(\".\"):\n","            continue\n","        # Open image and convert any grayscale to RBG.\n","        I = Image.open(os.path.join(path, imageName)).convert('RGB')\n","        newI = transformationForCNNInput(I)\n","\n","        # sav images to CNN path\n","        newI.save(os.path.join(searchDirCNN, imageName))\n","        \n","        newI.close()\n","        I.close()"]},{"cell_type":"markdown","metadata":{},"source":["<h1 style=\"font-family: 'Times New Roman'\">Vectorize Search Images</h1>\n","\n","Applies the CNN vectorization to the folder of search images"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["img2vec = Img2VecResnet18() \n","\n","searchVectors = {}\n","print(\"Converting images to feature vectors:\")\n","for image in tqdm(os.listdir(\"searchImagesCNN\")):\n","    if image.startswith(\".\"):\n","        continue\n","    I = Image.open(os.path.join(\"searchImagesCNN\", image)).convert('RGB')\n","    vec = img2vec.getVec(I)\n","    searchVectors[image] = vec\n","    I.close()"]},{"cell_type":"markdown","metadata":{},"source":["<h1 style=\"font-family: 'Times New Roman'\">Cosine Similarity</h1>\n","\n","Cosine similarity is a method of measuring the similarity between two vectors. It returns a value from 0 to 1 with 1 meaning most similar and 0 meaning least."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from resources import cosine_similarity"]},{"cell_type":"markdown","metadata":{},"source":["<h1 style=\"font-family: 'Times New Roman'\">Print Search Options</h1>\n","\n","Currently, query options are stored in a seperate folder for easy access and use. This cell iterates through this folder printing the names and images of the search options."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for image in searchVectors.keys():\n","    print(image + \":\")\n","    im = Image.open(searchDir + \"/\" + image)\n","    display(im)"]},{"cell_type":"markdown","metadata":{},"source":["<h1 style=\"font-family: 'Times New Roman'\">Image Query and Search</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["query = \"Frida_Kahlo_3.jpg\"\n","v1 = searchVectors[query]\n","#make a list of images\n","similarity=list(allVectors.keys())\n","#sort list by similarity to query\n","similarity.sort(key = lambda x: cosine_similarity(v1, allVectors[x]), reverse = True)"]},{"cell_type":"markdown","metadata":{},"source":["<h1 style=\"font-family: 'Times New Roman'\">Image Similarities</h1>\n","\n","Using the vectors generated with our CNN and cosine similarity, we will fins the most similar images in the dataset to our query. The first image is the query used for our search, followed by the most similar photos to the query. If the query is contained in the dataset, the closest image should return itself with a similarity of 1."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Search query:\")\n","img = Image.open(os.path.join(searchDir, query))\n","display(img)\n","print(\"Related Images: \")\n","#print 10 most similar images\n","for image in similarity[:10]:\n","    print(image)\n","    print(\"similarity: \" + str(cosine_similarity(searchVectors[query], allVectors[image])))\n","    img = Image.open(os.path.join(paths[image], image))\n","    display(img)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":2}
